<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Dgraph Blog</title>
    <link>http://blog.dgraph.io/</link>
    <description>Recent content on Dgraph Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Copyright (c) 2016, Dgraph Labs, Inc. All rights reserved.</copyright>
    <lastBuildDate>Tue, 21 Jun 2016 10:20:32 +0530</lastBuildDate>
    <atom:link href="http://blog.dgraph.io/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>How much can you handle?</title>
      <link>http://blog.dgraph.io/post/performance-throughput-latency/</link>
      <pubDate>Tue, 21 Jun 2016 10:20:32 +0530</pubDate>
      
      <guid>http://blog.dgraph.io/post/performance-throughput-latency/</guid>
      <description>

&lt;p&gt;In this post, we’ll look at how Dgraph performs on varying the number of nodes in the cluster, specs of the machine and load on the server.&lt;/p&gt;

&lt;h2 id=&#34;about-the-dataset&#34;&gt;About the Dataset&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Freebase&#34;&gt;Freebase&lt;/a&gt; is an online collection of structured data which includes contributions from many sources including individual and user-generated contributions.
Currently, it has &lt;a href=&#34;https://developers.google.com/freebase/&#34;&gt;1.9 Billion RDF N-Triples&lt;/a&gt; worth 250GB of uncompressed data.
On top of that, this dataset is over 95% accurate with a complex and rich real world schema.
It is an ideal data set to test the performance of Dgraph.
We decided not to use the entire data set as it wasn&amp;rsquo;t necessary for our goal here.&lt;/p&gt;

&lt;p&gt;Given our love for movies, we narrowed it down to the film data.
We ran some scripts and filtered in the movie data only.
All the data and scripts are present in &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/tree/master/data&#34;&gt;our benchmarks repository&lt;/a&gt;.
There are two million nodes, which represent directors, actors, films and all the other objects in the database.
Moreover, 21 million edges (including 4M edges for names) are representing the relationships between actors, films, directors and all the other nodes in the database.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Some interesting information about this data:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# film.film --{film.film.starring}--&amp;gt; [mediator] --{film.performance.actor}--&amp;gt; film.actor
# Film --&amp;gt; Mediator
$ zgrep &amp;quot;&amp;lt;film.film.starring&amp;gt;&amp;quot; rdf-films.gz | wc -l
1397647

# Mediator --&amp;gt; Actor
$ zgrep &amp;quot;&amp;lt;film.performance.actor&amp;gt;&amp;quot; rdf-films.gz | wc -l
1396420

# Film --&amp;gt; Director
$ zgrep &amp;quot;&amp;lt;film.film.directed_by&amp;gt;&amp;quot; rdf-films.gz | wc -l
242212

# Director --&amp;gt; Film
$ zgrep &amp;quot;&amp;lt;film.director.film&amp;gt;&amp;quot; rdf-films.gz | wc -l
245274

# Film --&amp;gt; Initial Release Date
$ zgrep &amp;quot;&amp;lt;film.film.initial_release_date&amp;gt;&amp;quot; rdf-films.gz | wc -l
240858

# Film --&amp;gt; Genre
$ zgrep &amp;quot;&amp;lt;film.film.genre&amp;gt;&amp;quot; rdf-films.gz | wc -l
548152

# Genre --&amp;gt; Film
$ zgrep &amp;quot;&amp;lt;film.film_genre.films_in_this_genre&amp;gt;&amp;quot; rdf-films.gz | wc -l
546698

# Generated language names from names freebase rdf data.
$ zcat langnames.gz | awk &#39;{print $1}&#39; | uniq | sort | uniq | wc -l
55

# Total number of countries.
$ zgrep &amp;quot;&amp;lt;film.film.country&amp;gt;&amp;quot; rdf-films.gz | awk &#39;{print $3}&#39; | uniq | sort | uniq | wc -l
304
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;This data set contains information about ~480K actors, ~100K directors and ~240K films.
Some example of entries in the dataset are :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;m.0102j2vq&amp;gt; &amp;lt;film.actor.film&amp;gt; &amp;lt;m.011kyqsq&amp;gt; .
&amp;lt;m.0102xz6t&amp;gt; &amp;lt;film.performance.film&amp;gt; &amp;lt;m.0kv00q&amp;gt; .
&amp;lt;m.050llt&amp;gt; &amp;lt;type.object.name&amp;gt; “Aishwarya Rai Bachchan”@hr .
&amp;lt;m.0bxtg&amp;gt; &amp;lt;type.object.name&amp;gt; “Tom Hanks”@es .
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;terminology&#34;&gt;Terminology&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Throughput: Number of queries served by the server per second and received by the client&lt;/li&gt;
&lt;li&gt;Latency: Difference between the time when the server received the request and the time it finished processing the request&lt;/li&gt;
&lt;li&gt;95 percentile latency: The worst case latency which 95 percentage of users that query the database face&lt;/li&gt;
&lt;li&gt;50 percentile latency: The worst case latency which half the users that query the database face&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;setup&#34;&gt;Setup&lt;/h2&gt;

&lt;p&gt;All the testing was done on GCE instances. Each machine had 30GB of SSD and at least 7.5 GB of RAM. The number of cores varied depending on the experiments performed.&lt;/p&gt;

&lt;p&gt;The tests were run for 1-minute intervals during which all the parallel connections made requests to the database.
This was repeated ten times and throughput, mean latency, 95th percentile latency, 50th percentile latency were measured.
Note that for user-facing systems, measuring percentile latency is better than mean latency as the average can be skewed by outliers.&lt;/p&gt;

&lt;p&gt;In a multi-node cluster set up, the queries were distributed among each node in a round-robin fashion.
Note that no single machine contains all the data to answer these queries, in a multi-node cluster.
They still have to communicate with each other to respond to the queries.&lt;/p&gt;

&lt;h2 id=&#34;variables&#34;&gt;Variables&lt;/h2&gt;

&lt;p&gt;The parameters that were varied were:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;A number of parallel connections to the database. In Go, this equated to the number of goroutines a client would have. Each goroutine would run in an infinite loop, querying the database via a blocking function.&lt;/li&gt;
&lt;li&gt;Number of cores per server&lt;/li&gt;
&lt;li&gt;Number of servers in the cluster&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This gave us an idea of what to expect from the system and would help in predicting the configuration required to handle a given load.&lt;/p&gt;

&lt;h2 id=&#34;queries&#34;&gt;Queries&lt;/h2&gt;

&lt;p&gt;We ran broadly 2 categories of queries.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;For each actor (478,936 actors), get their name, the films they acted in, and those films&amp;rsquo; names.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;{
  me ( _xid_ : XID ) {
    type.object.name.en
    film.actor.film {
      film.performance.film {
        type.object.name.en
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;For each director (90,063 directors), get their name, the films they directed, and names of all the genres of those films.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;{
  me ( _xid_ : XID ) {
    type.object.name.en
    film.director.film {
      film.film.genre {
        type.object.name.en
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;During each iteration, either an actor or a director category was chosen randomly.
Furthermore, for that category, an actor or director was chosen randomly; their &lt;code&gt;XID&lt;/code&gt; filled in in the query template.&lt;/p&gt;

&lt;h2 id=&#34;performance&#34;&gt;Performance&lt;/h2&gt;

&lt;p&gt;Let us look at some graphs obtained by varying the machine specs and the number of nodes in the cluster under different loads.&lt;/p&gt;

&lt;h3 id=&#34;vary-the-number-of-cores-in-a-single-instance&#34;&gt;Vary the number of cores in a single instance&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.dgraph.io/images/cores_thru.jpg&#34; alt=&#34;Throughput on varying number of cores&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.dgraph.io/images/cores_lat_50.jpg&#34; alt=&#34;50 percentile latency on varying number of cores&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.dgraph.io/images/cores_lat_95.jpg&#34; alt=&#34;95 percentile latency on varying number of cores&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.dgraph.io/images/cores_lat_mean.jpg&#34; alt=&#34;mean latency on varying number of cores&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;With the same number of cores, when we increase the number of connections, i.e. load on the system, the throughput as well as the latency increase.&lt;/li&gt;
&lt;li&gt;Throughput increases till some point and then flattens out. This is the point where the computational capacity is being utilized almost fully.&lt;/li&gt;
&lt;li&gt;As expected, the latency increases almost linearly with the number of connections.&lt;/li&gt;
&lt;li&gt;When we increase the number of cores, the latency decreases and the throughput increases.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;vary-number-of-instances&#34;&gt;Vary number of instances&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.dgraph.io/images/topo_thru.jpg&#34; alt=&#34;Throughput on varying number of instances&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.dgraph.io/images/dist_lat_50.jpg&#34; alt=&#34;50 percentile latency on varying number of instances&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.dgraph.io/images/dist_lat_95.jpg&#34; alt=&#34;95 percentile latency on varying number of instances&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.dgraph.io/images/dist_lat_mean.jpg&#34; alt=&#34;mean latency on varying number of instances&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;When we increase the number of parallel connections, the throughput increases, but then flattens out. This is the point where the computational capacity is being utilized almost fully.&lt;/li&gt;
&lt;li&gt;The latency increases almost linearly with the number of connections.&lt;/li&gt;
&lt;li&gt;Latency in the case of a single instance is observed to be the equal to (or a bit lower than) that of distributed configurations as the former doesn’t require any network calls. However, as the number of requests/load increase, the cumulative computational power comes into play and overshadows the latency incurred due to network calls. Hence, the latency reduces in the distributed version under higher loads.&lt;/li&gt;
&lt;li&gt;On comparing across the one, two and five node clusters, we can see that the latency, as well as the throughput, are better for configurations with a higher number of nodes, i.e., when there is more computational capacity at disposal. The throughput increases as we have greater computational power and can handle more queries.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;From the above experiments, we can see a relationship between the throughput, latency and the overall computational power of the cluster.
The graphs show that the throughput increases as the computational power increases.
Which can be achieved either by increasing the number of cores on each server or the number of nodes in the cluster.&lt;/p&gt;

&lt;p&gt;The latency increases as the amount of load on the database increases.
However, the rate of the increase differs based on how much computational power we have available.&lt;/p&gt;

&lt;p&gt;This experiment also shows that there is a limit on how much computational power a single node can have, and once we reach that limit, scaling horizontally is the right option.
Not only that, but it also proves that scaling horizontally improves the performance.
Hence, having more replicas, distributing the dataset optimally across machines are some factors which help in improving the throughput and reducing the latency that the users face.&lt;/p&gt;

&lt;p&gt;Based on this experiment, our recommendation for running Dgraph would be:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Use as many cores as possible&lt;/li&gt;
&lt;li&gt;Have the servers geographically close-by so that network latency is reduced&lt;/li&gt;
&lt;li&gt;Distribute the data among servers and query them in a round-robin fashion for greater throughput&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These might seem pretty obvious recommendations for a distributed system (duh!), but this experiment proves that the underlying design of Dgraph is scalable.
Hope this helped you get a sense of what sort of performance you could expect out of Dgraph!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This post is derived from my report for B.tech Project on “A Distributed Implementation of the Graph Database System, Dgraph”.
The full report is &lt;a href=&#34;https://www.dropbox.com/s/7h4ytak39r2pdun/Ashwin_Thesis.pdf?dl=0&#34;&gt;available for download here&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;If you or your company plan to use a graph database, you can &lt;a href=&#34;http://dgraph.io&#34;&gt;see our live demo here&lt;/a&gt;.
If deep and complex open source distributed systems interest you, &lt;a href=&#34;http://dgraph.io&#34;&gt;join us. We are hiring!&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Check out our &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34;&gt;Github repository&lt;/a&gt;.
Then find us on &lt;a href=&#34;https://discuss.dgraph.io&#34;&gt;discuss.dgraph.io&lt;/a&gt; or &lt;a href=&#34;http://slack.dgraph.io&#34;&gt;Slack&lt;/a&gt;, and come talk to us.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;- Written by &lt;a href=&#34;https://twitter.com/ashwin_rrr&#34;&gt;Ashwin Ramesh&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;http://mars.nasa.gov/images/PIA14840.jpg&#34;&gt;Mars Rover Landing via Nasa&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hello, World!</title>
      <link>http://blog.dgraph.io/post/hello-world/</link>
      <pubDate>Mon, 18 Apr 2016 14:37:08 +1000</pubDate>
      
      <guid>http://blog.dgraph.io/post/hello-world/</guid>
      <description>&lt;p&gt;&lt;strong&gt;I&amp;rsquo;m very excited&lt;/strong&gt; to use this first post to talk about Dgraph, what it is and why it was created.&lt;/p&gt;

&lt;p&gt;Before I explain what&amp;rsquo;s Dgraph, let&amp;rsquo;s start with a basic understanding of graphs.
A graph is a mathematical structure used to model a pairwise relationship between entities.
A graph is thus composed of nodes connected by edges.
Each node represents an entity (a person, place, thing, etc.), and each edge represents the relationship between two nodes.
Some popular graphs that we all know about are the &lt;a href=&#34;https://en.wikipedia.org/wiki/Social_graph&#34;&gt;Facebook Social Graph&lt;/a&gt; and the &lt;a href=&#34;https://en.wikipedia.org/wiki/Knowledge_Graph&#34;&gt;Google Knowledge Graph&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;A graph database is a database that uses graph structures with nodes and edges to represent, store and serve data.&lt;/p&gt;

&lt;p&gt;But who really uses graph databases? More teams and companies than you&amp;rsquo;d think.
Google, Facebook, Twitter, eBay, LinkedIn, Amazon, Dropbox, Pinterest &amp;ndash; pick a company you are familiar with.
If they&amp;rsquo;re doing something smart, chances are they&amp;rsquo;re probably using a graph database.
Even very simple web apps have much to gain from graph databases.
In the past, I&amp;rsquo;ve built a graph based REST framework and using that &lt;a href=&#34;https://mrjn.xyz/post/Porting-To-Gocrud/&#34;&gt;cut down the code in half&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So now that we understand graphs, let&amp;rsquo;s talk about Dgraph.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Dgraph is an open source, low-latency, high throughput, native and distributed graph database.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;To understand why it was created, let&amp;rsquo;s rewind a few years back to 2011.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;I&amp;rsquo;d been at Google&lt;/strong&gt; about 4+ years with the Web Search Infrastructure Group.
Google had just then acquired Metaweb a year earlier in 2010.
I&amp;rsquo;d been wrapping my head around the newly acquired Knowledge Graph, trying to find ways to integrate Knowledge Graph with Google Search.
This is when I found a problem.&lt;/p&gt;

&lt;p&gt;At Google, we had multiple knowledge bearing feeds called One Boxes.
You know, the boxed snippets that sometimes show up at the top of the search results, for instance when you search for &lt;a href=&#34;https://www.google.com/#q=tesla+stock&#34;&gt;Tesla stock&lt;/a&gt;, &lt;a href=&#34;https://www.google.com/#q=weather+in+sydney&#34;&gt;Weather in Sydney&lt;/a&gt;, or &lt;a href=&#34;https://www.google.com/#q=events+in+san+francisco&#34;&gt;Events in San Francisco&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;There were multiple custom built backends, each serving a One Box.
A search query hitting &lt;em&gt;&lt;a href=&#34;https://www.google.com&#34;&gt;www.google.com&lt;/a&gt;&lt;/em&gt; would be sent iteratively through each of these One Box backends to check if any of them has a response.
When one of the backends responds, the One Box data is retrieved and rendered on the top of the search results page.
This is how that well-formatted box with just the right information shows up below the search bar, thus saving you a few clicks.&lt;/p&gt;

&lt;p&gt;As good as it sounded, One Boxes had several inefficiencies and missed opportunities.&lt;/p&gt;

&lt;p&gt;For starters, each One Box was custom built by a separate team that was responsible for running and maintaining it.
As a result, there was no particular sharing of the framework used to build the One Box.&lt;/p&gt;

&lt;p&gt;This also meant that there was no single standard for the data format used by the One Boxes.
Each One Box kept its data in its very own data structure, and no common querying language.
Thus, there didn&amp;rsquo;t exist an opportunity to share data amongst the boxes, to respond to more interesting queries that required an intersection of diverse data feeds.&lt;/p&gt;

&lt;p&gt;A good example of this would be the ability to &lt;em&gt;recommend events based on the weather&lt;/em&gt; to a tourist exploring NYC &amp;ndash; that couldn&amp;rsquo;t easily be done with the existing system.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.dgraph.io/images/nyc.jpg&#34; alt=&#34;NYC in rain&#34; /&gt;
&lt;em&gt;Courtesy: &lt;a href=&#34;https://flic.kr/p/azztBd&#34;&gt;Several Seconds&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;This motivated me to start a project to standardize the data structures and eventually serve them all using a single backend.
Using the vast expertise of Metaweb team, we chose a data normalization structure that was also used by Knowledge Graph, the RDF Triples.
By reconciling all the various entities from the different data feeds, we could start to reuse the data.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;But, there was a second and more challenging part to the problem.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;It was to build a system that could serve structured queries with data updating in real time.
The system had to run behind Web Search, which meant that if it doesn&amp;rsquo;t respond within allocated milliseconds, Search would time out and move on.
Also, this system had to tackle a major chunk of query load to Web Search, which amounts to thousands of queries per second.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;We basically had to build a low latency, high throughput system to serve graph queries.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;It was certainly an exciting project and held much promise.
But, the harsh realities of the business environment and the attendant politics resulted in the cancellation of the project.
Shortly thereafter I left Google in 2013 and didn&amp;rsquo;t give much thought to the project.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Fast forward two years,&lt;/strong&gt; I was hanging out on the Go language&amp;rsquo;s Slack channel and Stack Overflow.
I saw quite a few people complaining about a popular graph database&amp;rsquo;s performance and stability.&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s when I realized that graph databases were starting to be used more frequently than it would appear from the surface.
But a bit more digging around revealed a deeper problem.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Existing native graph databases weren&amp;rsquo;t designed to be performant or distributed.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The ones that sharded the data and distributed it across a cluster weren&amp;rsquo;t actually native graph databases.
They were largely serving as a graph layer over another database.
This meant having many network calls should the intermediate number of results be large, which leads to performance degradation.&lt;/p&gt;

&lt;p&gt;For example, say you wanted to find &lt;strong&gt;[People living in SF who eat Sushi]&lt;/strong&gt;.
Assuming you have this data (&lt;em&gt;hey Facebook!&lt;/em&gt;) and keeping things simple, this requires 2 steps.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.dgraph.io/images/sushi.jpg&#34; alt=&#34;Sushi&#34; /&gt;
&lt;em&gt;Courtesy: &lt;a href=&#34;https://flic.kr/p/nLkbkQ&#34;&gt;Yannig Van de Wouwer&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;First, you find all the people living in SF, and then secondly, intersect that list with all the people who eat Sushi.&lt;/p&gt;

&lt;p&gt;As you can imagine, the intermediate step here has a &lt;em&gt;large fan-out&lt;/em&gt;, i.e. there&amp;rsquo;re over a million results.
If you were to shard the data by &lt;em&gt;entities&lt;/em&gt; (people), you&amp;rsquo;d end up broadcasting to all the servers in the cluster.
Thus, this query would be affected by even a single slow machine in the cluster.&lt;/p&gt;

&lt;p&gt;Do that for every query, and it would spike the 95%-ile latency numbers up dramatically, &lt;em&gt;higher latency being worse&lt;/em&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Dgraph, on the other hand, is a native graph database&lt;/strong&gt; in the sense that the data is handled directly by Dgraph, and not given off to another database layer.&lt;/p&gt;

&lt;p&gt;This allows us to shard and relocate the data better, to minimize the number of network calls required per query.
In fact, the above query would run in 2 network calls, irrespective of the cluster size.&lt;/p&gt;

&lt;p&gt;The number of network calls being &lt;em&gt;directly proportional to the complexity of the query&lt;/em&gt;, not the number of intermediate or final results.&lt;/p&gt;

&lt;p&gt;Dgraph is designed to easily scale from meeting the needs of a small startup to that of Dropbox, or even Facebook.
This means being able to run on a laptop as well as on a big cluster of hundreds of machines serving thousands of queries per second.&lt;/p&gt;

&lt;p&gt;Additionally, it would also have to survive machine failures and partial data center collapses.
The data stored would have to be automatically replicated with no single point of failure, and be able to move around the cluster to better distribute traffic.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;This is the big vision which led to Dgraph.&lt;/strong&gt; And I&amp;rsquo;m &lt;a href=&#34;http://dgraph.io/&#34;&gt;fortunate to have a team&lt;/a&gt; that believes in and shares this vision with me.&lt;/p&gt;

&lt;p&gt;Apart from use with diverse social and knowledge graphs, Dgraph can also be used to:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;build real-time recommendation engines,&lt;/li&gt;
&lt;li&gt;do semantic search,&lt;/li&gt;
&lt;li&gt;pattern matching,&lt;/li&gt;
&lt;li&gt;serve relationship data, and&lt;/li&gt;
&lt;li&gt;serve web apps via &lt;a href=&#34;https://facebook.github.io/graphql/&#34;&gt;GraphQL&lt;/a&gt;, a full feature graph query language by Facebook.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We&amp;rsquo;ll be reporting some performance numbers for Dgraph in our next few posts, to give you an idea of what you can expect from the system.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;If you or your company plan to use a graph database, you can &lt;a href=&#34;http://dgraph.io&#34;&gt;see our live demo here&lt;/a&gt;.
We have big dreams for Dgraph, and if deep and complex open source distributed systems interest you, &lt;a href=&#34;http://dgraph.io&#34;&gt;come join us. We&amp;rsquo;re hiring!&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Check out our &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34;&gt;Github repository&lt;/a&gt;.
Then find us hanging out at &lt;a href=&#34;https://discuss.dgraph.io&#34;&gt;discuss.dgraph.io&lt;/a&gt; or &lt;a href=&#34;http://slack.dgraph.io&#34;&gt;Slack&lt;/a&gt;, and come talk to us.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;- Written by &lt;a href=&#34;https://twitter.com/manishrjain&#34;&gt;Manish R Jain&lt;/a&gt;&lt;/em&gt;. Thanks to &lt;a href=&#34;https://twitter.com/koppula&#34;&gt;Prashanth Koppula&lt;/a&gt; and the team for proofreading.
&lt;em&gt;Top image: &lt;a href=&#34;http://go.nasa.gov/1VlGVXx&#34;&gt;Mars Rover Curiosity in Buckskin Selfie&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>